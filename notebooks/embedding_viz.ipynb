{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "SAMPLE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mtsamples.csv\")\n",
    "print(len(df))\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "df[\"medical_specialty\"] = df[\"medical_specialty\"].map(lambda x: x.strip())\n",
    "\n",
    "SPECIALTIES = [\"Surgery\", \"Cardiovascular / Pulmonary\", \"Orthopedic\", \"Radiology\", \"General Medicine\"]\n",
    "df = df.loc[df.medical_specialty.isin(SPECIALTIES)]\n",
    "print(len(df))\n",
    "# Perform stratified sampling to get 100 samples per specialty\n",
    "sampled_dfs = []\n",
    "for specialty in SPECIALTIES:\n",
    "    specialty_df = df[df.medical_specialty == specialty]\n",
    "    # If there are fewer than SAMPLE_SIZE samples in a specialty, take all of them\n",
    "    if len(specialty_df) <= SAMPLE_SIZE:\n",
    "        sampled_dfs.append(specialty_df)\n",
    "        print(f\"{specialty}: using all {len(specialty_df)} available samples\")\n",
    "    else:\n",
    "        # Otherwise, sample SAMPLE_SIZE samples\n",
    "        sampled_dfs.append(specialty_df.sample(n=SAMPLE_SIZE, random_state=42))\n",
    "        print(f\"{specialty}: sampled {SAMPLE_SIZE} from {len(specialty_df)} available samples\")\n",
    "\n",
    "# Combine all sampled dataframes\n",
    "df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "# Display the distribution of specialties after sampling\n",
    "print(\"\\nDistribution after stratified sampling:\")\n",
    "print(df.medical_specialty.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Function to get embeddings for a text\n",
    "def get_embedding(text):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create embeddings for each transcription\n",
    "# Using tqdm for progress tracking and adding rate limiting to avoid API limits\n",
    "# Create a list to store embeddings with their corresponding indices\n",
    "embeddings_with_indices = []\n",
    "for idx, text in tqdm(enumerate(df['transcription'].tolist())):\n",
    "    embedding = get_embedding(text)\n",
    "    # Store both the embedding and its original index\n",
    "    embeddings_with_indices.append((idx, embedding))\n",
    "    time.sleep(0.1)  # Rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for embeddings, initialized with None values\n",
    "df['embedding'] = None\n",
    "\n",
    "# Only add embeddings that were successfully generated, using their original indices\n",
    "for idx, embedding in embeddings_with_indices:\n",
    "    if embedding is not None:\n",
    "        df.at[idx, 'embedding'] = embedding\n",
    "\n",
    "# Check if any embeddings failed\n",
    "failed_embeddings = df['embedding'].isna().sum()\n",
    "if failed_embeddings > 0:\n",
    "    print(f\"Warning: {failed_embeddings} embeddings failed to generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = df.loc[~df.embedding.isna()]\n",
    "dfe.to_csv(\"../data/mtsamples_with_embeddings_stratified.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mtsamples_with_embeddings_stratified.csv\")\n",
    "# k = 5\n",
    "\n",
    "# top_specialties = df.medical_specialty.value_counts().head(k).index.values\n",
    "# df = df.loc[df.medical_specialty.isin(top_specialties)]\n",
    "# top_specialties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the embedding strings to numpy arrays\n",
    "df['embedding'] = df['embedding'].apply(\n",
    "    lambda x: np.array(eval(x)) if isinstance(x, str) else None\n",
    ")\n",
    "\n",
    "# Filter out any rows with missing embeddings\n",
    "df_filtered = df.dropna(subset=['embedding'])\n",
    "\n",
    "# Extract embeddings as a list of arrays\n",
    "embeddings_list = df_filtered['embedding'].tolist()\n",
    "\n",
    "# Convert list of embeddings to a 2D numpy array\n",
    "embeddings_array = np.vstack(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE to reduce dimensions to 2D\n",
    "print(\"Applying t-SNE dimensionality reduction...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=500)\n",
    "embeddings_2d = tsne.fit_transform(embeddings_array)\n",
    "\n",
    "# Create a DataFrame with the 2D coordinates and medical specialty\n",
    "tsne_df = pd.DataFrame({\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1],\n",
    "    'medical_specialty': df_filtered['medical_specialty'].values\n",
    "})\n",
    "\n",
    "# Plot the t-SNE visualization\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(\n",
    "    data=tsne_df,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    hue='medical_specialty',\n",
    "    # palette='bright',\n",
    "    alpha=0.7,\n",
    "    s=100\n",
    ")\n",
    "\n",
    "# plt.title('Medical Transcriptions (text-embedded-3-large, t-SNE)', fontsize=16)\n",
    "# plt.xlabel('Dimension 1', fontsize=12)\n",
    "# plt.ylabel('Dimension 2', fontsize=12)\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the number of unique medical specialties\n",
    "print(f\"Number of unique medical specialties: {df_filtered['medical_specialty'].nunique()}\")\n",
    "print(f\"Total number of samples visualized: {len(df_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions to 2D\n",
    "print(\"Applying PCA dimensionality reduction...\")\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d_pca = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create a DataFrame with the 2D coordinates and medical specialty\n",
    "pca_df = pd.DataFrame({\n",
    "    'x': embeddings_2d_pca[:, 0],\n",
    "    'y': embeddings_2d_pca[:, 1],\n",
    "    'medical_specialty': df_filtered['medical_specialty'].values\n",
    "})\n",
    "\n",
    "# Plot the PCA visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    hue='medical_specialty',\n",
    "    palette='Set1',\n",
    "    alpha=0.7,\n",
    "    s=100\n",
    ")\n",
    "\n",
    "plt.title('Medical Transcriptions (text-embedding-3-large)', fontsize=16)\n",
    "plt.xlabel('Component 1', fontsize=12)\n",
    "plt.ylabel('Component 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
